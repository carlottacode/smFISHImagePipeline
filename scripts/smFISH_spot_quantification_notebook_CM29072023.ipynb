{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b18a9467",
   "metadata": {},
   "source": [
    "## Import the pipeline functions from functions.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f6314d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i functions_edit.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646e5f62",
   "metadata": {},
   "source": [
    "# USER INPUT - **please enter the parameters of your experiment:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8a05f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default is channels=['CY5', 'CY3', 'CY3.5', 'DAPI']\n",
    "channels = ['CY5', 'CY3.5', 'CY3', 'DAPI']\n",
    "\n",
    "# Number of Z-slices per channel (for Marah's data this is 41)\n",
    "number_zslices = 41\n",
    "\n",
    "# Default is colors=['magenta', 'green', 'cyan', 'blue']\n",
    "colors = ['magenta', 'green', 'cyan', 'blue']\n",
    "\n",
    "# Defaults is voxel_size=(200, 64.5, 64.5) in nanometers\n",
    "voxel_size=(200, 64.5, 64.5)\n",
    "\n",
    "# Default is spot_radius=(200, 70, 70)\n",
    "spot_radius=(200, 70, 70)\n",
    "\n",
    "#image scale in micrometres\n",
    "image_scale = (voxel_size[1]/1000, voxel_size[2]/1000)\n",
    "\n",
    "\n",
    "# Please add the paths to the three Cellpose models downloaded from the repo.\n",
    "pretrained_whole_model_path = \"C:/Users/lotta/Pictures/Cellpose/whole_DAPI+DIC/models/whole_model_993\"\n",
    "# If you do not wish to use the Cellpose models below set their value to None as follows: \n",
    "# pretrained_separate_model_path = None\n",
    "# pretrained_whole_SHIFTCORRECTED_model_path = None\n",
    "pretrained_separate_model_path = \"C:/Users/lotta/Pictures/Cellpose/sep_DAPI+DIC/models/sep_model_1180\"\n",
    "pretrained_whole_SHIFTCORRECTED_model_path = None\n",
    "\n",
    "yET916_BR2_03 = ['C:/Users/lotta/Documents/Bioinformatics_Msc/Project/DATA_INITIAL/pair_1/yET916-SUN4Q570-SRL1CFR610-ASH1CLB2Q670_03_CY5, CY3.5 NAR, CY3, DAPI.tif',\n",
    "                 \"C:/Users/lotta/Documents/Bioinformatics_Msc/Project/DATA_INITIAL/pair_1/yET916-SUN4Q570-SRL1CFR610-ASH1CLB2Q670_04_DIC-100.tif\"]\n",
    "\n",
    "# Please add the path of the TIF and DIC file you'd like to analyse with this pipeline\n",
    "tif_path = yET916_BR2_03[0]\n",
    "dic_path = yET916_BR2_03[1]\n",
    "\n",
    "# Please add the path to which you'd like to save the Dataframe containing the metrics calculates\n",
    "results_excel_path = 'C:/Users/lotta/Bioinformatics/smFISHimagepipeline/pipeline_outputs/output_yET916_BR2_03.xlsx'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbfc40d6",
   "metadata": {},
   "source": [
    "#### Read corresponding DIC and TIF images and split the TIF file into the four channels\n",
    "- \"corresponding_files\" is a list of the corresponding file names. \n",
    "- \"stack_example\" is an array of the 41 z-slices for each of the 4 channels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4d94bf",
   "metadata": {},
   "source": [
    "### Load TIF and DIC image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "207f7b96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 164/164 [00:02<00:00, 80.28it/s]\n"
     ]
    }
   ],
   "source": [
    "corresponding_files, image_stack = read_stack([tif_path, dic_path], number_zslices, channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343bb490",
   "metadata": {},
   "source": [
    "#### For each channel create a Maximum Intensity Projection for each channel\n",
    "- For each channel there are 40 slices of these not all are in focus, if the \"in-focus-zslices\" are known they can be input into the function. \n",
    "- If not a laplacian operator can be used to select these \"in-focus-zslices\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe6e735c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Maximum Intensity Projections for each channel\n",
    "# Each MIP image array is iteratively added to the projection list.\n",
    "projection = []\n",
    "for i in image_stack:\n",
    "    # Instead of choose_focus_lap(i) the focussed slices can be \n",
    "    # input in the form [first in focus slice, last in focus slice]\n",
    "    infocus_slices = choosing_in_focus_slices(i, number_of_slices=12)\n",
    "    projection.append(generating_maximum_projection(i, infocus_slices))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f056ac",
   "metadata": {},
   "source": [
    "#### View the MIPs alongside the DIC in napari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a54b18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the MIPs in napari.\n",
    "viewer= napari.Viewer()\n",
    "napari_view(corresponding_files, np.array(projection), channels, colors, image_scale)\n",
    "viewer.scale_bar.visible = True\n",
    "viewer.scale_bar.unit = \"um\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6daf9e6f",
   "metadata": {},
   "source": [
    "## Detect the mRNA spots for each of the zslices in each channel\n",
    "- \"spot_coord_dict\" is a dictionary where the key is each channel and the value is an array of the mRNA coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80b995d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNA detection for each channel.\n",
    "spot_coord_dict = detecting_mRNA_spots(image_stack, voxel_size, spot_radius, channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4f479c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "spot_dict_df = saving_spot_dict_in_df(spot_coord_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a92ff43",
   "metadata": {},
   "source": [
    "#### View the MIPs alongside the DIC with the detected spots in napari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "afc7e5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer= napari.Viewer()\n",
    "napari_view(corresponding_files, np.array(projection), channels, colors, image_scale)\n",
    "napari_view_spots(corresponding_files, np.array(projection), spot_coord_dict, channels, colors, image_scale)\n",
    "viewer.scale_bar.visible = True\n",
    "viewer.scale_bar.unit = \"um\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001973d3",
   "metadata": {},
   "source": [
    "# Cellpose\n",
    "#### Load pre-trained models\n",
    "- These can be substituted with any user-trained model and there is no need to use two, this is simply for mother-bud analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a8283f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_model = models.CellposeModel(pretrained_model=pretrained_whole_model_path)\n",
    "if pretrained_separate_model_path != None:\n",
    "    sep_model = models.CellposeModel(pretrained_model=pretrained_separate_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30975e5e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "05142bde",
   "metadata": {},
   "source": [
    "#### Create a two channel image with the DAPI MIP and the DIC image to generate Cellpose masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6a3d8f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_dictionary = split_stack(image_stack, channels, colors)\n",
    "in_focus_slices = choosing_in_focus_slices(channel_dictionary['DAPI'][1], number_of_slices=15)\n",
    "dapi_projection = (generating_maximum_projection(channel_dictionary['DAPI'][1], in_focus_slices))\n",
    "cellpose_input = [io.imread(corresponding_files[1]), dapi_projection]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0aeef2",
   "metadata": {},
   "source": [
    "#### Choose images to create masks of using the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b4876637",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = np.array(cellpose_input)\n",
    "nimg = len(imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ae0f81",
   "metadata": {},
   "source": [
    "#### Evaluate the images and return masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "49eec417",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define CHANNELS to run segementation on\n",
    "# grayscale=0, R=1, G=2, B=3\n",
    "# channels = [cytoplasm, nucleus]\n",
    "# if NUCLEUS channel does not exist, set the second channel to 0\n",
    "cellpose_channels = [[1,2]]\n",
    "masks_whole, whole_flows, whole_styles = whole_model.eval(imgs, diameter=None, channels=cellpose_channels)\n",
    "if pretrained_separate_model_path != None:\n",
    "    masks_sep, sep_flows, sep_styles = sep_model.eval(imgs, diameter=None, channels=cellpose_channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df55f1f1",
   "metadata": {},
   "source": [
    "# Oppurtunity to view and correct masks using napari\n",
    "#### Using the labels layer in napari you are able to use paintbrush and eraser tools to edit the masks. \n",
    "- Use the dropper tool to match the colour of the mask you want to edit. \n",
    "- Or simply use any colour to draw a new one on. \n",
    "- Use the shuffle colours button to check that your edit, of i.e. addition to a mask, is recognised as part of the mask. \n",
    "    - If this is working correctly when you shuffle colours the edit and the old mask should change to the same colour as one. \n",
    "#### Once you have edited as desired please save the masks in a tif file\n",
    "- This can be done within napari by going to --> save selected layers and then saving in your file system. \n",
    "- Note down where you have saved this image as you will be asked for a path of this to continue with the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ee1b748f",
   "metadata": {},
   "outputs": [],
   "source": [
    "napari_check_and_edit_masks(masks_whole, corresponding_files[1], \"Whole\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "06e48ebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: QWindowsWindow::setGeometry: Unable to set geometry 1280x1104+0+34 (frame: 1302x1160-11-11) on QWidgetWindow/\"_QtMainWindowClassWindow\" on \"\\\\.\\DISPLAY1\". Resulting geometry: 1280x1102+0+34 (frame: 1302x1158-11-11) margins: 11, 45, 11, 11 minimum size: 374x551 MINMAXINFO maxSize=0,0 maxpos=0,0 mintrack=770,1158 maxtrack=0,0)\n"
     ]
    }
   ],
   "source": [
    "if pretrained_separate_model_path != None:\n",
    "    napari_check_and_edit_masks(masks_sep, corresponding_files[1], \"Separate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fdfe237",
   "metadata": {},
   "source": [
    "# USER INPUT - if you have edited the masks please put the corrected mask paths below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bc3e2423",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_whole_masks_path = \"C:/Users/lotta/Pictures/corrected_cellpose_masks/whole_masks_corrected.tif\"\n",
    "corrected_sep_masks_path = \"C:/Users/lotta/Pictures/corrected_cellpose_masks/sep_masks_corrected.tif\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486707b2",
   "metadata": {},
   "source": [
    "#### Continuing with the pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3b456d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "masks_whole = loading_corrected_masks(masks_whole, corrected_whole_masks_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6b773b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "if pretrained_separate_model_path != None:\n",
    "    masks_sep = loading_corrected_masks(masks_whole, corrected_sep_masks_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "706fd54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "projection_dict = create_mip_projection_dict(channels, projection)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77004ab1",
   "metadata": {},
   "source": [
    "### Assign mRNA spots to individual cells\n",
    "##### For the 'separate' masks i.e. the mother and the bud are two separate units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a0802999",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load masks of both Cellpose models.\n",
    "spots_per_cell_whole_masks = extracting_spots_per_cell(spot_coord_dict, masks_whole, projection_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06366e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "spots_per_cell_whole_masks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13386fc4",
   "metadata": {},
   "source": [
    "## Work out the DIC shift using the proportion of mRNA spots in cells vs outside of them "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "46b3e0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "proportion_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a324dc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default is channels=['rna_coord', 'CY3', 'CY3.5']\n",
    "spot_channels = list(spot_coord_dict.keys())\n",
    "spot_channels[0] = 'rna_coord'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ca810bb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original proportion of mRNA spots per cell: 78.32151111819559\n",
      "Current maximum proportion 82.13 and the cooresponding coordinates: [-1, 1]\n",
      "Current maximum proportion 84.96 and the cooresponding coordinates: [-2, 2]\n",
      "Current maximum proportion 87.66 and the cooresponding coordinates: [-3, 3]\n",
      "Current maximum proportion 89.82 and the cooresponding coordinates: [-4, 4]\n",
      "Current maximum proportion 91.46 and the cooresponding coordinates: [-5, 5]\n",
      "Current maximum proportion 92.71 and the cooresponding coordinates: [-6, 6]\n",
      "Current maximum proportion 93.42 and the cooresponding coordinates: [-7, 7]\n",
      "Current maximum proportion 93.61 and the cooresponding coordinates: [-8, 8]\n",
      "Current maximum proportion 93.67 and the cooresponding coordinates: [-9, 8]\n",
      "Current maximum proportion 93.69 and the cooresponding coordinates: [-10, 7]\n"
     ]
    }
   ],
   "source": [
    "prop, cells, total = counting_spots_in_cells(spot_coord_dict, spots_per_cell_whole_masks, spot_channels)\n",
    "print(f'Original proportion of mRNA spots per cell: {prop}')\n",
    "dic_shift_info = finding_max_proportion_of_image(prop, 0, 0, proportion_dict, spot_coord_dict, masks_whole, projection_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f13743f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[93.68773411970989, [-10, 7]]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic_shift_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4995b1",
   "metadata": {},
   "source": [
    "# Cellpose part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "270d87c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if pretrained_whole_SHIFTCORRECTED_model_path != None:\n",
    "    shiftcorrected_whole_model = models.CellposeModel(pretrained_model=pretrained_whole_SHIFTCORRECTED_model_path)\n",
    "    dapi_projection_shifted = shift(dapi_projection,  [-dic_shift_info[1][0],-dic_shift_info[1][1]])\n",
    "    cellpose_input = [io.imread(corresponding_files[1]), dapi_projection_shifted]\n",
    "    #\n",
    "    cellpose_imgs = np.array(cellpose_input)\n",
    "    nimg = len(imgs)\n",
    "    #\n",
    "    shiftmodel_masks_whole, shiftmodel_whole_flows, shiftmodel_whole_styles = shiftcorrected_whole_model.eval(cellpose_imgs, diameter=None, channels=cellpose_channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657daef9",
   "metadata": {},
   "source": [
    "### Per cell mRNA coordinates with the shift "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bb2222f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if pretrained_separate_model_path != None:\n",
    "    mask_sep_shifted = shift(masks_sep, dic_shift_info[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "079d39fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if pretrained_whole_SHIFTCORRECTED_model_path != None:\n",
    "    mask_whole_shifted = shift(shiftmodel_masks_whole, dic_shift_info[1])\n",
    "else:\n",
    "    mask_whole_shifted = shift(masks_whole, dic_shift_info[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "45185763",
   "metadata": {},
   "outputs": [],
   "source": [
    "spots_per_cell_whole_shifted = extracting_spots_per_cell(spot_coord_dict, mask_whole_shifted, projection_dict)\n",
    "if pretrained_separate_model_path != None:\n",
    "    spots_per_cell_sep_shifted = extracting_spots_per_cell(spot_coord_dict, mask_sep_shifted, projection_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ef845a",
   "metadata": {},
   "source": [
    "### Find the corresponding mother and bud segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c66f645d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{13: ('bud', 'corresponding mother: 15'), 15: ('mother', 'corresponding bud: 13'), 16: ('mother', 'corresponding bud: 19'), 19: ('bud', 'corresponding mother: 16'), 26: ('mother', 'corresponding bud: 30'), 30: ('bud', 'corresponding mother: 26'), 28: ('bud', 'corresponding mother: 31'), 31: ('mother', 'corresponding bud: 28'), 33: ('mother', 'corresponding bud: 37'), 37: ('bud', 'corresponding mother: 33'), 38: ('bud', 'corresponding mother: 41'), 41: ('mother', 'corresponding bud: 38'), 45: ('bud', 'corresponding mother: 47'), 47: ('mother', 'corresponding bud: 45'), 49: ('bud', 'corresponding mother: 51'), 51: ('mother', 'corresponding bud: 49'), 54: ('mother', 'corresponding bud: 62'), 62: ('bud', 'corresponding mother: 54'), 56: ('mother', 'corresponding bud: 60'), 60: ('bud', 'corresponding mother: 56'), 59: ('mother', 'corresponding bud: 70'), 70: ('bud', 'corresponding mother: 59'), 76: ('mother', 'corresponding bud: 85'), 85: ('bud', 'corresponding mother: 76'), 83: ('bud', 'corresponding mother: 86'), 86: ('mother', 'corresponding bud: 83'), 84: ('mother', 'corresponding bud: 90'), 90: ('bud', 'corresponding mother: 84'), 89: ('bud', 'corresponding mother: 93'), 93: ('mother', 'corresponding bud: 89'), 102: ('bud', 'corresponding mother: 106'), 106: ('mother', 'corresponding bud: 102'), 113: ('bud', 'corresponding mother: 115'), 115: ('mother', 'corresponding bud: 113'), 129: ('bud', 'corresponding mother: 130'), 130: ('mother', 'corresponding bud: 129')}\n"
     ]
    }
   ],
   "source": [
    "# Assign the mother and bud fragments to eachother using the centre points of the masks.\n",
    "if pretrained_separate_model_path != None:\n",
    "    centroid_dict = mask_centroids(mapping_mask_coordinates(spots_per_cell_sep_shifted))\n",
    "    motherbud_pairs = mother_bud_reunion(mapping_mask_coordinates(spots_per_cell_whole_shifted), centroid_dict)\n",
    "    motherbud_dict = mother_or_bud(motherbud_pairs, spots_per_cell_sep_shifted) # fov index : mother or bud\n",
    "    print(motherbud_dict)\n",
    "else:\n",
    "    motherbud_dict = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a020d2c",
   "metadata": {},
   "source": [
    "#### View shifted masks with spots on MIPs with the corresponding DIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e276d87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer = napari.Viewer()\n",
    "napari_view(corresponding_files, np.array(projection), channels, colors, image_scale)\n",
    "napari_view_spots(corresponding_files, np.array(projection), spot_coord_dict, channels, colors, image_scale)\n",
    "napari_view_masks(mapping_mask_coordinates(spots_per_cell_whole_shifted),  image_scale, \"Whole Masks\", mask_colors=['pink'])\n",
    "if pretrained_separate_model_path != None:\n",
    "    napari_view_masks(mapping_mask_coordinates(spots_per_cell_sep_shifted), image_scale, \"Separate Masks\", mask_colors=['lightblue'])\n",
    "viewer.scale_bar.visible = True\n",
    "viewer.scale_bar.unit = \"um\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d247ab9c",
   "metadata": {},
   "source": [
    "# Put all the information in a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "61a18a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i bigfish_function.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "63f69bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "spot_im_channels = list(projection_dict.keys())\n",
    "spot_im_channels.remove('DAPIP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "515920b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if pretrained_separate_model_path != None:\n",
    "    sep_df = writing_metrics_to_DataFrame(spots_per_cell_sep_shifted, spot_channels, spot_im_channels, motherbud_dict, image_scale, dic_shift_info)\n",
    "else:\n",
    "    sep_df = None\n",
    "whole_df = writing_metrics_to_DataFrame(spots_per_cell_whole_shifted, spot_channels, spot_im_channels, None, image_scale, dic_shift_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d0357d",
   "metadata": {},
   "source": [
    "## Save DataFrame as an Excel File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b9d24255",
   "metadata": {},
   "outputs": [],
   "source": [
    "writing_dataframe_to_excel(results_excel_path, whole_df, sep_df, spot_dict_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
